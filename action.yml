name: "Ollama Runner Action"
description: "Install and run Ollama with specified models"
author: "Your Name"

inputs:
  model:
    description: "Ollama model to use (e.g., llama2, codellama, mistral)"
    required: true
    default: "smollm2:135m"
outputs:
  server-url:
    description: "URL of the Ollama server"
    value: ${{ steps.verify-server.outputs.server-url }}
  status:
    description: "Status of the Ollama server"
    value: ${{ steps.verify-server.outputs.status }}
runs:
  using: "composite"
  steps:
    # Platform Detection
    - name: Detect Platform
      id: platform
      shell: bash
      run: |
        case "$(uname -s)" in
          Linux*)     echo "platform=linux" >> $GITHUB_OUTPUT;;
          Darwin*)    echo "platform=macos" >> $GITHUB_OUTPUT;;
          MINGW64*)   echo "platform=windows" >> $GITHUB_OUTPUT;;
          *)         echo "Unknown platform" && exit 1;;
        esac

    # Linux Installation
    - name: Install Ollama (Linux)
      if: steps.platform.outputs.platform == 'linux'
      shell: bash
      run: |
        curl -fsSL https://ollama.ai/install.sh | sh
        echo "Installed Ollama for Linux"

    - name: Install Ollama (macOS)
      if: steps.platform.outputs.platform == 'macos'
      shell: bash
      run: |
        # Check if Homebrew is installed, install if not
        if ! command -v brew &> /dev/null; then
          echo "Installing Homebrew..."
          /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
        fi

        # Install coreutils and Ollama using Homebrew
        echo "Installing dependencies and Ollama using Homebrew..."
        brew install coreutils ollama

        echo "Ollama installed successfully"

    - name: Install Ollama (Windows)
      if: steps.platform.outputs.platform == 'windows'
      shell: pwsh
      run: |
        Write-Host "Installing Ollama for Windows..."

        try {
          # Define installation paths
          $ollamaDir = "C:\ollama"
          $ollamaExe = "C:\ollama\ollama.exe"

          # Create installation directory
          if (-not (Test-Path $ollamaDir)) {
            New-Item -Path $ollamaDir -ItemType Directory -Force
          }

          # Get latest release info
          $apiLatestUrl = "https://api.github.com/repos/ollama/ollama/releases/latest"
          $latestRelease = Invoke-RestMethod -Uri $apiLatestUrl
          $zipUrl = $latestRelease.assets | Where-Object { $_.name -match "windows-amd64\.zip$" } | Select-Object -ExpandProperty browser_download_url

          # Download and extract
          Write-Host "Downloading Ollama from $zipUrl"
          Invoke-WebRequest -Uri $zipUrl -OutFile "$ollamaDir\ollama.zip"

          Write-Host "Extracting Ollama..."
          Expand-Archive -Path "$ollamaDir\ollama.zip" -DestinationPath $ollamaDir -Force

          # Verify installation
          if (-not (Test-Path $ollamaExe)) {
            throw "Ollama executable not found after installation"
          }

          # Add to PATH and make it available to subsequent steps
          $env:PATH = "$ollamaDir;$env:PATH"
          echo "PATH=$env:PATH" >> $env:GITHUB_ENV

          # Export the installation path for other steps
          echo "OLLAMA_DIR=$ollamaDir" >> $env:GITHUB_ENV
          echo "OLLAMA_EXE=$ollamaExe" >> $env:GITHUB_ENV

          Write-Host "Ollama installed successfully at: $ollamaExe"
          Write-Host "Current PATH: $env:PATH"

        } catch {
          Write-Host "Error during installation: $_"
          Write-Host $_.ScriptStackTrace
          exit 1
        } finally {
          # Cleanup
          if (Test-Path "$ollamaDir\ollama.zip") {
            Remove-Item "$ollamaDir\ollama.zip" -Force
          }
        }
    # Start Ollama Server (Platform Independent)
    - name: Start Ollama Server
      shell: bash
      run: |
        echo "Starting Ollama server..."

        if [ "${{ steps.platform.outputs.platform }}" = "windows" ]; then
          # Windows-specific start using full path
          OLLAMA_EXE="C:/ollama/ollama.exe"
          echo "Starting Ollama from: $OLLAMA_EXE"

          powershell -Command "& {
            try {
              if (-not (Test-Path '$OLLAMA_EXE')) {
                throw 'Ollama executable not found at: $OLLAMA_EXE'
              }

              Start-Process '$OLLAMA_EXE' -ArgumentList 'serve' -NoNewWindow -RedirectStandardOutput ollama.log -RedirectStandardError ollama_error.log

              Write-Host 'Ollama server process started'
            } catch {
              Write-Host 'Error starting Ollama: $_'
              exit 1
            }
          }"
        else
          # Unix-like systems (Linux/macOS)
          ollama serve > ollama.log 2>&1 &
          echo $! > ollama.pid
        fi

        # Server readiness check
        echo "Waiting for server to be ready..."
        TIMEOUT=30
        READY=0
        while [ $TIMEOUT -gt 0 ]; do
          if [ "${{ steps.platform.outputs.platform }}" = "windows" ]; then
            powershell -Command "
              if (Test-NetConnection -ComputerName localhost -Port 11434 -WarningAction SilentlyContinue) {
                exit 0
              } else {
                exit 1
              }
            " && READY=1 && break
          else
            curl -s http://localhost:11434/api/version >/dev/null && READY=1 && break
          fi
          echo "Waiting for server... ($TIMEOUT seconds remaining)"
          sleep 1
          TIMEOUT=$((TIMEOUT - 1))
        done

        if [ $READY -eq 0 ]; then
          echo "Failed to start Ollama server"
          cat ollama.log
          [ -f ollama_error.log ] && cat ollama_error.log
          exit 1
        fi

        echo "Ollama server is running"

    # Pull Model
    - name: Pull Model
      shell: bash
      run: |
        echo "Starting model pull for ${{ inputs.model }}..."

        if ollama pull ${{ inputs.model }}; then
          echo "Model pulled successfully!"
        else
          echo "Error pulling model (Exit code: $?)"
          exit 1
        fi

    - name: Verify Server Status
      id: verify-server # Add this ID
      shell: bash
      run: |
        SERVER_URL="http://localhost:11434"

        if curl -s "$SERVER_URL/api/version" >/dev/null; then
          echo "Ollama server is running and ready for use"
          echo "Server is available at $SERVER_URL"
          echo "server-url=$SERVER_URL" >> $GITHUB_OUTPUT
          echo "status=running" >> $GITHUB_OUTPUT
        else
          echo "Server verification failed"
          echo "status=failed" >> $GITHUB_OUTPUT
          exit 1
        fi
